# Belief Extraction Pipeline Flow

This document visualizes the complete belief extraction pipeline, showing how utterances are processed from raw transcript to final belief matrix.

## Pipeline Overview

```mermaid
flowchart TD
    A["ðŸ“„ Start: Transcript File
    Diarized text with speaker labels
    ðŸ“œ run_multilevel_extraction.py"] --> B["ðŸ” Parse Transcript
    Extract speaker, timestamp, text
    ðŸ“œ transcript_parser.py::parse_file()"]
    
    B --> C["âœ‚ï¸ Split into Utterances
    Each line becomes one utterance
    ðŸ“œ transcript_parser.py::Utterance"]
    
    C --> D{"ðŸ”„ For Each Utterance
    Process 1 by 1 or in parallel
    ðŸ“œ extractor.py::extract_from_file()"}
    
    D --> E["ðŸš¦ Stage 1: Belief Filter
    Q1: Contains identifiable belief?
    Q2: Reveals what speaker believes?
    Q3: Endorsed by speaker?
    Q4: Reveals worldview/preferences?
    ðŸ“œ classifier.py::stage1_filter()"]
    
    E --> F{"â“ Is Belief?
    Check filter confidence score
    ðŸ“œ classifier.py::classify()"}
    
    F -->|"âŒ No - 70% filtered out"| G["â­ï¸ Skip
    Questions, ads, greetings"]
    
    F -->|"âœ… Yes - 30% pass filter"| H["âš¡ Extract Atomic Beliefs
    NEW: Clean standalone statements
    ðŸ“œ classifier.py::extract_atomic_beliefs()"]
    
    H --> I["ðŸŽ¯ Get Statement + Certainty
    binary or hedged classification
    ðŸ“œ prompts/atomic_belief_extraction.txt"]
    
    I --> J["ðŸ§  Stage 2: Full Classification
    26+ analysis questions via LLM
    ðŸ“œ classifier.py::stage2_classify()"]
    
    J --> K["ðŸ† Determine Primary Tier
    Which of 10 tiers fits best
    ðŸ“œ prompts/stage2_classify.txt"]
    J --> L["ðŸ“Š Generate 10 Abstractions
    Core Axioms â†’ Loose Takes
    ðŸ“œ prompts/tier_abstraction.txt"]
    J --> M["ðŸ’ª Conviction & Stability
    How strong + how stable 0-1
    ðŸ“œ prompts/stage2_classify.txt"]
    J --> N["ðŸŒ Score 4 Domains
    Sci/tech, phil/religious, financial, political
    ðŸ“œ prompts/stage2_classify.txt"]
    J --> O["ðŸ·ï¸ Assign Category
    epistemic, moral, political, etc.
    ðŸ“œ prompts/stage2_classify.txt"]
    
    K --> P["ðŸ“¦ Compile Belief Record
    Combine all fields into one row
    ðŸ“œ classifier.py::BeliefClassification"]
    L --> P
    M --> P
    N --> P
    O --> P
    I --> P
    
    P --> Q{"ðŸ” More Utterances?
    Continue until all processed
    ðŸ“œ classifier.py::classify_batch()"}
    
    Q -->|Yes| D
    Q -->|No| R["ðŸ—‚ï¸ Create DataFrame
    Convert to pandas table
    ðŸ“œ extractor.py::_to_dataframe()"]
    
    R --> S["âž• Add New Columns
    atomic_belief, certainty + 14 others
    ðŸ“œ extractor.py::_to_dataframe()"]
    
    S --> T["ðŸ’¾ Save Output
    CSV/Parquet with all weights
    ðŸ“œ multilevel_extractor.py::save_output()"]
    
    T --> U["ðŸ“ˆ Calculate Summary Stats
    Counts, averages, costs
    ðŸ“œ multilevel_extractor.py::get_cost_stats()"]
    
    U --> V["âœ¨ Display Results
    Total beliefs, speakers, cost
    ðŸ“œ run_multilevel_extraction.py"]
    
    classDef newFeature fill:#90EE90,stroke:#2d5016,stroke-width:2px,color:#000
    classDef aiStep fill:#87CEEB,stroke:#104e8b,stroke-width:2px,color:#000
    classDef dataStep fill:#FFE4B5,stroke:#8b6914,stroke-width:2px,color:#000
    
    class H,I,S newFeature
    class E,J aiStep
    class R,T,U dataStep
```

## Legend

- ðŸŸ¢ **Green boxes**: New atomic belief extraction features
- ðŸ”µ **Blue boxes**: AI/LLM processing steps (API calls)
- ðŸŸ¡ **Yellow boxes**: Data transformation steps

## Stage Details

### Stage 1: Belief Filter

Determines if an utterance contains a belief using 4 questions:

1. **Q1**: Contains identifiable belief or value judgment?
2. **Q2**: Reveals what the speaker believes (even implicitly)?
3. **Q3**: Is this belief endorsed or sympathetically discussed by the speaker?
4. **Q4**: Does this reveal anything about the speaker's worldview or preferences?

**Passing criteria**: Q2, Q3, Q4 all YES OR confidence â‰¥ 0.6

### Atomic Belief Extraction (NEW)

Extracts clean, standalone belief statements from each utterance:
- Removes questions, quotes, narration, fluff
- Preserves speaker's intent and framing
- Classifies certainty: "binary" (absolute) or "hedged" (uncertain)

**Examples:**
- Input: "I think Bitcoin is going to be huge"
  - Atomic: "Bitcoin is going to be huge"
  - Certainty: "hedged"

- Input: "Bitcoin follows a power law, not exponential growth"
  - Atomic: "Bitcoin follows a power law"
  - Certainty: "binary"

### Stage 2: Full Classification

Comprehensive analysis generating:
- **Primary tier** (1-10): Best-fit tier from Core Axioms â†’ Loose Takes
- **10 tier abstractions**: Reformulated at each abstraction level
- **Tier fit scores** (1-10): How well the belief fits each tier
- **Conviction score** (0-1): How strongly speaker holds this belief
- **Stability score** (0-1): How long-term/stable the belief is
- **4 domain scores** (0-1): Scientific/tech, philosophical/religious, financial, political
- **Category**: epistemic, moral, political, economic, etc.

## Final Output Schema

The final CSV/Parquet includes:

| Column | Description |
|--------|-------------|
| `belief_id` | Unique identifier |
| `speaker_id` | Speaker from transcript |
| `episode_id` | Episode identifier |
| `timestamp` | Time in transcript |
| `statement_text` | Original full utterance |
| `atomic_belief` | âœ¨ Clean standalone statement |
| `certainty` | âœ¨ "binary" or "hedged" |
| `importance` | Primary tier (1-10) |
| `tier_name` | Tier label |
| `category` | Belief category |
| `conviction_score` | Speaker conviction (0-1) |
| `stability_score` | Long-term stability (0-1) |
| `parent_hint` | Parent belief description |
| `parent_belief_id` | Linked parent ID |

âœ¨ = New atomic belief extraction fields

## Performance

- **Sequential mode**: ~15-20 min for 200 utterances
- **Parallel mode** (10 workers): ~4-6 min for 200 utterances
- **Typical pass rate**: 30% of utterances become beliefs
- **Cost**: ~$0.80-2.50 per full 9k word podcast

## Usage

```bash
# Single-level extraction
python run_multilevel_extraction.py --transcript input.txt --levels 1

# Parallel processing (2-4x faster)
python run_multilevel_extraction.py --transcript input.txt --levels 1 --parallel --max-workers 10

# Test with cheap mode
python run_multilevel_extraction.py --transcript input.txt --levels 1 --cheap-mode --no-wandb

# Multi-level extraction (default)
python run_multilevel_extraction.py --transcript input.txt --episode-id e_001
```

